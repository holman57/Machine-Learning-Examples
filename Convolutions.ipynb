{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6a9a4c95-52c5-4a52-9c06-7d9cfa112a6f",
      "metadata": {
        "id": "6a9a4c95-52c5-4a52-9c06-7d9cfa112a6f"
      },
      "source": [
        "# Convolutions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20616413-31a2-4caa-b4f6-6f014d3225b5",
      "metadata": {
        "id": "20616413-31a2-4caa-b4f6-6f014d3225b5"
      },
      "source": [
        "$$\n",
        "(f∗g)(i,j) = ∑_a ∑_b f(a,b)g(i−a,j−b)\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c7a6afe-8343-478d-a82e-c598ab59463d",
      "metadata": {
        "id": "7c7a6afe-8343-478d-a82e-c598ab59463d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def conv2d(image, kernel):\n",
        "    H, W = list(image.size())\n",
        "    M, N = list(kernel.size())\n",
        "\n",
        "    out = torch.zeros(H-M+1, W-N+1, dtype=torch.float32)\n",
        "    for i in range(H-M+1):\n",
        "        for j in range(W-N+1):\n",
        "            out[i,j]= torch.sum(image[i:i+M,j:j+N]*kernel)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "259bbadf-d1aa-416b-a8bd-baa1e592332b",
      "metadata": {
        "id": "259bbadf-d1aa-416b-a8bd-baa1e592332b"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "conv_layer = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=5)\n",
        "print(conv_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1758fb3-c6cd-4048-a31c-321b2cb90480",
      "metadata": {
        "id": "a1758fb3-c6cd-4048-a31c-321b2cb90480"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "input_img = torch.rand(1,3,7,7)\n",
        "layer = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=2, padding=1)\n",
        "out = layer(input_img)\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e41faad-daf9-4792-8b9d-668c6929654c",
      "metadata": {
        "id": "0e41faad-daf9-4792-8b9d-668c6929654c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "input_img = torch.rand(1,3,8,8)\n",
        "layer = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "out = layer(input_img)\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55af436b-7f1d-4f8b-8d28-5442189e1865",
      "metadata": {
        "id": "55af436b-7f1d-4f8b-8d28-5442189e1865"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}